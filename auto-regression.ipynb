{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "io_params = {\n",
    "    'parse_dates': ['epoch']\n",
    "}\n",
    "\n",
    "train = pd.read_csv('data/train.csv', **io_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:17<00:00, 35.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import tqdm\n",
    "\n",
    "dtypes = train.dtypes.to_dict()\n",
    "\n",
    "cols_to_shift = train.columns.difference(['x_sim', 'y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim'])\n",
    "\n",
    "train_sats = []\n",
    "\n",
    "for sat_id in tqdm.tqdm(train['sat_id'].unique(), position=0):\n",
    "    \n",
    "    g = train.query('sat_id == @sat_id').copy()\n",
    "    dups = g[g['epoch'].diff() < dt.timedelta(seconds=60)].index\n",
    "    \n",
    "    for i in reversed(dups):\n",
    "        g.loc[i:, cols_to_shift] = g.loc[i:, cols_to_shift].shift(-1)\n",
    "        \n",
    "    g = g.drop(g[g['x'].isnull()].index)\n",
    "    g['percent'] = pd.np.arange(1, len(g) + 1) / len(g)\n",
    "        \n",
    "    train_sats.append(g)\n",
    "    \n",
    "train = pd.concat(train_sats).astype(dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/Track 1/test.csv', **io_params)\n",
    "data = pd.concat((train, test), sort=False)\n",
    "data['is_train'] = data['x'].notnull()\n",
    "data = data.sort_values(['sat_id', 'epoch'])\n",
    "data['is_track_1'] = data['sat_id'].isin(data.query('not is_train')['sat_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement SMAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def smape(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a generic auto-regressive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARModel:\n",
    "    \n",
    "    def __init__(self, p, model):\n",
    "        self.p = p\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, path):\n",
    "        \n",
    "        n = path.strides[0]\n",
    "        X = np.lib.stride_tricks.as_strided(path, shape=(path.shape[0], self.p), strides=(n, n))[:-self.p]\n",
    "        Y = path[self.p:]\n",
    "        \n",
    "        # Save the most recent history for later usage\n",
    "        # Conceptually history is a list, but we give it an extra dimension because sklearn eats matrices\n",
    "        self.history = path[-self.p:].reshape(1, -1)\n",
    "        \n",
    "        self.model.fit(X, Y)\n",
    "        \n",
    "    def forecast(self, steps):\n",
    "        \n",
    "        history = self.history.copy()\n",
    "        predictions = np.empty(steps)\n",
    "        \n",
    "        for i in range(steps):\n",
    "            \n",
    "            y_pred = self.model.predict(history)[0]    \n",
    "            predictions[i] = y_pred\n",
    "            \n",
    "            # Shift forward (faster than np.roll)\n",
    "            history[0, :-1] = history[0, 1:]\n",
    "            history[0, -1] = y_pred\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:40<00:00, 14.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import compose\n",
    "from sklearn import linear_model\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "import tqdm\n",
    "\n",
    "preds = []\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    \"\"\"Barebones implementation with less overhead than sklearn.\"\"\"\n",
    "    \n",
    "    def __init__(self, *steps):\n",
    "        self.steps = steps\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for transformer in self.steps[:-1]:\n",
    "            X = transformer.fit_transform(X, y)\n",
    "        self.steps[-1].fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        for transformer in self.steps[:-1]:\n",
    "            X = transformer.transform(X)\n",
    "        return self.steps[-1].predict(X)\n",
    "\n",
    "\n",
    "class StandardScaler(preprocessing.StandardScaler):\n",
    "    \"\"\"Barebones implementation with less overhead than sklearn.\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return (X - self.mean_) / self.var_ ** .5\n",
    "    \n",
    "    \n",
    "class LinearRegression(linear_model.LinearRegression):\n",
    "    \"\"\"Barebones implementation with less overhead than sklearn.\"\"\"\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.coef_) + self.intercept_\n",
    "\n",
    "    \n",
    "model = ARModel(\n",
    "    p=48,\n",
    "    model=Pipeline(\n",
    "        StandardScaler(),\n",
    "        LinearRegression()\n",
    "    )\n",
    ")\n",
    "\n",
    "train = data.query('is_train')\n",
    "\n",
    "for sat, g in tqdm.tqdm(train.assign(is_fit=train.eval('percent < .6')).groupby('sat_id'), position=0):\n",
    "\n",
    "    fit = g.query('is_fit')\n",
    "    val = g.query('not is_fit')\n",
    "\n",
    "    for var in ('x', 'y', 'z', 'Vx', 'Vy', 'Vz'):\n",
    "\n",
    "        model.fit(fit[var].to_numpy())\n",
    "        pred = model.forecast(len(val))\n",
    "\n",
    "        preds.append(pd.DataFrame({\n",
    "            'sat_id': sat,\n",
    "            'epoch': val['epoch'],\n",
    "            'y_true': val[var],\n",
    "            'y_pred': pred,\n",
    "            'variable': var\n",
    "        }))\n",
    "        \n",
    "preds = pd.concat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.57179531257634"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smapes = preds.groupby(['sat_id', 'variable']).apply(lambda g: smape(g['y_true'], g['y_pred']))\n",
    "mean_smape = smapes.mean()\n",
    "100 * (1 - mean_smape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the validation SMAPEs for further comparison and blending with other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat_id,variable,smape\r\n",
      "0,Vx,0.000597070177374541\r\n",
      "0,Vy,0.00036367390081294725\r\n",
      "0,Vz,0.0001728272296867911\r\n",
      "0,x,0.0017613854434870993\r\n",
      "0,y,0.00025717133886025544\r\n",
      "0,z,0.0006687014398263775\r\n",
      "1,Vx,0.0031092783186345996\r\n",
      "1,Vy,0.0009305197946845225\r\n",
      "1,Vz,0.003728780888035956\r\n"
     ]
    }
   ],
   "source": [
    "smapes.rename('smape').to_csv('results/ar_val_scores.csv', header=True)\n",
    "!head results/ar_val_scores.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:34<00:00,  8.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat_id</th>\n",
       "      <th>id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3927</td>\n",
       "      <td>2014-02-01 00:01:45.162</td>\n",
       "      <td>-24791.216496</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3928</td>\n",
       "      <td>2014-02-01 00:22:57.007</td>\n",
       "      <td>-21087.026330</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3929</td>\n",
       "      <td>2014-02-01 00:44:08.852</td>\n",
       "      <td>-16579.831302</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3930</td>\n",
       "      <td>2014-02-01 01:05:20.697</td>\n",
       "      <td>-11202.732371</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3931</td>\n",
       "      <td>2014-02-01 01:26:32.542</td>\n",
       "      <td>-4934.229045</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sat_id    id                   epoch        y_pred variable\n",
       "0       1  3927 2014-02-01 00:01:45.162 -24791.216496        x\n",
       "1       1  3928 2014-02-01 00:22:57.007 -21087.026330        x\n",
       "2       1  3929 2014-02-01 00:44:08.852 -16579.831302        x\n",
       "3       1  3930 2014-02-01 01:05:20.697 -11202.732371        x\n",
       "4       1  3931 2014-02-01 01:26:32.542  -4934.229045        x"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "train_sats = data.query('is_train and is_track_1')\n",
    "test_sats = data.query('not is_train and is_track_1')\n",
    "\n",
    "for sat in tqdm.tqdm(test_sats['sat_id'].unique(), position=0):\n",
    "\n",
    "    train = train_sats.query('sat_id == @sat')\n",
    "    test = test_sats.query('sat_id == @sat')\n",
    "\n",
    "    for var in ('x', 'y', 'z', 'Vx', 'Vy', 'Vz'):\n",
    "\n",
    "        model.fit(train[var].to_numpy())\n",
    "        pred = model.forecast(len(test))\n",
    "\n",
    "        preds.append(pd.DataFrame({\n",
    "            'sat_id': test['sat_id'],\n",
    "            'id': test['id'],\n",
    "            'epoch': test['epoch'],\n",
    "            'y_pred': pred,\n",
    "            'variable': var\n",
    "        }))\n",
    "        \n",
    "preds = pd.concat(preds)\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are melted, so we unmelt them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>sat_id</th>\n",
       "      <th>id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3927</td>\n",
       "      <td>2014-02-01 00:01:45.162</td>\n",
       "      <td>2.614250</td>\n",
       "      <td>-1.303894</td>\n",
       "      <td>1.087091</td>\n",
       "      <td>-24791.216496</td>\n",
       "      <td>-10910.678758</td>\n",
       "      <td>6570.591143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3928</td>\n",
       "      <td>2014-02-01 00:22:57.007</td>\n",
       "      <td>3.219142</td>\n",
       "      <td>-0.994539</td>\n",
       "      <td>0.895780</td>\n",
       "      <td>-21087.026330</td>\n",
       "      <td>-12384.401306</td>\n",
       "      <td>7840.063865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3929</td>\n",
       "      <td>2014-02-01 00:44:08.852</td>\n",
       "      <td>3.877770</td>\n",
       "      <td>-0.539693</td>\n",
       "      <td>0.601826</td>\n",
       "      <td>-16579.831302</td>\n",
       "      <td>-13379.440557</td>\n",
       "      <td>8806.129427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3930</td>\n",
       "      <td>2014-02-01 01:05:20.697</td>\n",
       "      <td>4.582811</td>\n",
       "      <td>0.157078</td>\n",
       "      <td>0.134822</td>\n",
       "      <td>-11202.732371</td>\n",
       "      <td>-13655.956823</td>\n",
       "      <td>9298.513352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3931</td>\n",
       "      <td>2014-02-01 01:26:32.542</td>\n",
       "      <td>5.251436</td>\n",
       "      <td>1.293476</td>\n",
       "      <td>-0.653268</td>\n",
       "      <td>-4934.229045</td>\n",
       "      <td>-12796.448989</td>\n",
       "      <td>9015.294227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variable  sat_id    id                   epoch        Vx        Vy        Vz  \\\n",
       "0              1  3927 2014-02-01 00:01:45.162  2.614250 -1.303894  1.087091   \n",
       "1              1  3928 2014-02-01 00:22:57.007  3.219142 -0.994539  0.895780   \n",
       "2              1  3929 2014-02-01 00:44:08.852  3.877770 -0.539693  0.601826   \n",
       "3              1  3930 2014-02-01 01:05:20.697  4.582811  0.157078  0.134822   \n",
       "4              1  3931 2014-02-01 01:26:32.542  5.251436  1.293476 -0.653268   \n",
       "\n",
       "variable             x             y            z  \n",
       "0        -24791.216496 -10910.678758  6570.591143  \n",
       "1        -21087.026330 -12384.401306  7840.063865  \n",
       "2        -16579.831302 -13379.440557  8806.129427  \n",
       "3        -11202.732371 -13655.956823  9298.513352  \n",
       "4         -4934.229045 -12796.448989  9015.294227  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = preds.groupby('sat_id').apply(lambda g: g.pivot_table(index=['id', 'epoch'], columns='variable', values='y_pred')).reset_index()\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take into account the shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:02<00:00, 107.25it/s]\n"
     ]
    }
   ],
   "source": [
    "correct_preds = []\n",
    "\n",
    "cols_to_shift = ['x', 'y', 'z', 'Vx', 'Vy', 'Vz']\n",
    "\n",
    "for _, g in tqdm.tqdm(preds.groupby('sat_id'), position=0):\n",
    "    \n",
    "    g = g.copy()\n",
    "    dups = g[g['epoch'].diff() < dt.timedelta(seconds=60)].index\n",
    "    \n",
    "    for i in dups:\n",
    "        g.loc[i:, cols_to_shift] = g.loc[i:, cols_to_shift].shift()\n",
    "    g[cols_to_shift] = g[cols_to_shift].ffill()\n",
    "    \n",
    "    correct_preds.append(g)\n",
    "    \n",
    "correct_preds = pd.concat(correct_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predictions for track 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,x,y,z,Vx,Vy,Vz\r\n",
      "3927,-24791.2164964244,-10910.678757601678,6570.591142685114,2.6142500911099793,-1.3038936610685328,1.087090864077235\r\n",
      "3928,-21087.026330143868,-12384.401305849937,7840.063864809641,3.21914249547442,-0.9945388414207295,0.8957800688453443\r\n",
      "3929,-16579.83130214371,-13379.440557068334,8806.129427121368,3.8777700588719823,-0.5396932773126031,0.6018263508983139\r\n",
      "3930,-11202.732370859037,-13655.956823114855,9298.513352163576,4.5828110631897845,0.1570784377916751,0.13482178502176748\r\n"
     ]
    }
   ],
   "source": [
    "correct_preds[['id', 'x', 'y', 'z', 'Vx', 'Vy', 'Vz']].to_csv('results/ar_track_1.csv', index=False)\n",
    "!head -5 results/ar_track_1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:06<00:00, 48.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "models = {}\n",
    "\n",
    "train_sats = data.query('is_train and not is_track_1')  # is_track_2 = not is_track_1 \n",
    "\n",
    "for sat, g in tqdm.tqdm(train_sats.groupby('sat_id'), position=0):\n",
    "    \n",
    "    models[sat] = {}\n",
    "\n",
    "    for col in ('x', 'y', 'z', 'Vx', 'Vy', 'Vz'):\n",
    "\n",
    "        path = g[col].to_numpy()\n",
    "        model.fit(path)\n",
    "        models[sat][col] = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the models and the histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8M\ttrack_2/ar_models.pkl\r\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(models, 'track_2/ar_models.pkl')\n",
    "!du -h track_2/ar_models.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
